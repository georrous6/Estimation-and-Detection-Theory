\documentclass[12pt]{article} % Font size 12pt

\usepackage{graphicx}      % For including images
\usepackage{caption}       % For customizing captions
\usepackage{subcaption}    % For subfigures within a figure

\usepackage{fontspec}
\usepackage{polyglossia}
\usepackage{geometry}
\usepackage{hyperref} % For hyperlinks
\usepackage{enumitem}

\usepackage{tikz}
\usepackage{pgf}
\usepackage{amsmath} % for math environments and symbols
\usepackage{amssymb}
\usetikzlibrary{arrows.meta}

\usepackage{comment}
\usepackage{ifthen}
\newboolean{showexamples}
\setboolean{showexamples}{true}  % or false to hide examples
% example boxes
\usepackage{tcolorbox}
\newtcolorbox{examplebox}[1]{%
  colback=white,
  colframe=gray!30,
  title={#1},
  sharp corners,
  boxrule=0.5pt,
  coltitle=black
}

\hypersetup{
    colorlinks=true,
    linkcolor=black,   % Internal links, those generated by cross-referenced elements
    filecolor=black,  % Links to local files
    urlcolor=black,    % Links to web sites
    citecolor=black,
}

\renewenvironment{examplebox}[1]{%
  \ifthenelse{\boolean{showexamples}}%
    {\begin{tcolorbox}[colback=white, colframe=gray!30, title={#1}, sharp corners, boxrule=0.5pt, coltitle=black]}%
    {\expandafter\comment}%
}{%
  \ifthenelse{\boolean{showexamples}}%
    {\end{tcolorbox}}%
    {\expandafter\endcomment}%
}

% Set fonts
\setmainfont{CMU Serif}
\newfontfamily\greekfont{CMU Serif}

% Define \greekfonttt
\newfontfamily\greekfonttt{DejaVu Sans Mono}[Script=Greek]

% Set languages
\setdefaultlanguage{greek}
\setotherlanguage{english}

\usepackage{multicol} % For multi-column sections
% \usepackage{array}

\usepackage{listings}
\usepackage{xcolor}

\lstset{
    language=Matlab,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    numbersep=5pt,
    backgroundcolor=\color{white},
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    frame=single,
    tabsize=2,
    captionpos=b,
    breaklines=true,
    breakatwhitespace=false,
    escapeinside={%}{)}
}
}


% Set margins
\geometry{
    top=0cm,
    bottom=2cm,
    left=2cm,
    right=2cm
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Εργασία Μέρος Β - Θεωρία Εκτίμησης και Ανίχνευσης}
\author{%
  \underline{Ομάδα 29} \\
  \begin{tabular}{ccc}
  Αριστείδης Δασκαλόπουλος & \  & Γεώργιος Ρουσομάνης \\
  arisdask@ece.auth.gr & \  & rousman@ece.auth.gr \\ 
  ΑΕΜ: 10640 & \  & ΑΕΜ: 10703
  \end{tabular}
}

\date{Ιούνιος 2025}

\begin{document}

\maketitle

\section*{Εισαγωγή}

\begin{center}
    \textit{Στόχος: Αποθορυβοποίηση πολυκαναλικών ΗΕΓ σημάτων, $\mathbf{y}[k] \in \mathbb{R}^N$, \\ που περιέχουν παρεμβολές λόγω ανοιγοκλεισίματος ματιών (blinks).}
\end{center}

\noindent\textrightarrow\ Το σήμα $y[k]$ μοντελοποιείται ως:

\vspace{-8pt}

\[
\mathbf{y}[k] = \mathbf{v}[k] + \mathbf{d}[k], \quad\text{$k \in \{1, \ldots, K\}$ με $K$ το πλήθος των μετρήσεων},
\]

\vspace{-5pt}

όπου: 
\begin{itemize}[noitemsep, nolistsep]
    \item $\mathbf{v}[k]$ είναι το καθαρό δυναμικό/σήμα από την δραστηριότητα του εγκεφάλου,
    \item $\mathbf{d}[k]$ ο θόρυβος (artifact).
\end{itemize}

\vspace{+10pt}

\noindent\textrightarrow\ Για την αποθορυβοποίηση των δεδομένων με Wiener φίλτρο θα εξετάσουμε δύο μεθόδους: 
\begin{enumerate}[noitemsep, nolistsep]
    \item Στην πρώτη\textemdash offline\textemdash μέθοδο (\textit{Sections 1.*}), θα προσπαθήσουμε να εκτιμήσουμε τα καθαρά δυναμικά 
    
    \vspace{-8pt}
    
    \[
    \theta = [\mathbf{v}[0], \mathbf{v}[1], \ldots, \mathbf{v}[K-1]],
    \]
    
    \vspace{-3pt}
    
    με βάση τις τρέχουσες, παρελθοντικές και μελλοντικές τιμές 
    $[\mathbf{y}[0], \ldots, \mathbf{y}[K-1]]$\textemdash 
    \textit{Smoothing}.

    \item Στη δεύτερη\textemdash online\textemdash μέθοδο (\textit{Section 2}), θα εκτιμήσουμε καθένα από τα

    \vspace{-8pt}
    
    \[
    \theta = \mathbf{v}[k],
    \]

    \vspace{-3pt}
    
    με βάση \textit{μόνο} τις τρέχουσες και παρελθοντικές τιμές των μετρήσεων, 
    $[\mathbf{y}[0], \ldots, \mathbf{y}[k]]$\textemdash \textit{Filtering}.
\end{enumerate}

\vspace{+7pt}

\noindent\textrightarrow\ Για την αρχική περίπτωση, που εφαρμόζουμε την Smoothing μέθοδο, ακολουθούμε δύο προσεγγίσεις. 
Στην πρώτη\textemdash μονοκαναλική\textemdash προσέγγιση (\textit{Section 1.1}) κάθε κανάλι θα αντιμετωπίζεται ανεξάρτητα από τα υπόλοιπα, 
ενώ στην δεύτερη\textemdash πολυκαναλική\textemdash (\textit{Section 1.2}) θα λαμβάνεται υπόψιν η συσχέτιση μεταξύ των καναλιών. 
\textit{Υπενθυμίζουμε ότι ο θόρυβος που οφείλεται στο ανοιγοκλείσιμο των ματιών είναι εντονότερος στα μετωπιαία ηλεκτρόδια.}

\begin{examplebox}{Σχόλιο}
    Παρουσιάζουμε και τις δύο προσεγγίσεις αν και περιμένουμε καλύτερα αποτελέσματα στην πολυκαναλική\textemdash μιας και σε αυτήν συνυπολογίζουμε την συσχέτιση μεταξύ των καναλιών. 
    Αυτό που έχει αξία να συγκρίνουμε μεταξύ των δύο είναι το πόσο μεγάλη θα είναι η διαφορά των σφαλμάτων που εισάγει η αποθορυβοποίηση στην πράξη. 
    Από αυτήν την διαφορά θα εξάγουμε συμπεράσματα για το κατά πόσο επηρεάζει ο συνυπολογισμός της συσχέτιση μεταξύ των καναλιών την ακρίβεια των αποτελεσμάτων μας. 
\end{examplebox}

\newpage

% Set margins
\newgeometry{
    top=2cm,
    bottom=2cm,
    left=2cm,
    right=2cm
}

\section*{1.1 \ Smoothing: \textit{Μονοκαναλικό} Wiener}
\noindent Για το $i$-οστό κανάλι συμβολίζουμε ως:

\vspace{-10pt}

\begin{center}
    $\mathbf{y}_i$: τις μετρήσεις, \hspace{1cm}
    $\mathbf{v}_i$: το καθαρό δυναμικό, \hspace{1cm}
    $\mathbf{d}_i$: τον θόρυβο, 
\end{center}

\vspace{-10pt}

% \begin{itemize}[noitemsep, nolistsep]
%     \item $\mathbf{y}_i$ τις μετρήσεις, 
%     \item $\mathbf{v}_i$ το καθαρό δυναμικό, και 
%     \item $\mathbf{d}_i$ τον θόρυβο
% \end{itemize}
\noindent για τις χρονικές στιγμές $k = 0, \ldots, K - 1$.

\vspace{+10pt}

Η εκτίμηση του φίλτρου Wiener είναι:

\vspace{-10pt}

\[
\hat{\mathbf{v}}_i = \mathbf{C}_{vy}^{(i)}\left(C_{yy}^{(i)}\right)^{-1}\mathbf{y}_i, \quad i = 1,...,N,
\]

\vspace{-7pt}
\noindent με $\mathbf{C}_{vy}^{(i)}$ τον πίνακα συνδιασποράς των $\mathbf{v}_i$ \& $\mathbf{y}_i$, και $C_{yy}^{(i)}$ τον πίνακα αυτοδιασποράς του $\mathbf{y}_i$.


\vspace{+2pt}

\noindent Αν θεωρήσουμε ότι τα $\mathbf{y}_i$, $\mathbf{v}_i$, και $\mathbf{d}_i$ είναι \textbf{\textit{σήματα μηδενικής μέσης τιμής}} 
(οι χρονοσειρές των $\mathbf{y}_i$ δεν απορρίπτουν αυτήν την υπόθεση), 
και ότι τα $\mathbf{v}_i$ και $\mathbf{d}_i$ είναι μεταξύ τους ανεξάρτητα, έχουμε:

\vspace{-7pt}

\[
\begin{aligned}
    \mathbf{C}_{yy}^{(i)} &= \mathbb{E}[\mathbf{y}_i\mathbf{y}_i^T] = \mathbf{R}_{yy}^{(i)} \\
    \mathbf{C}_{vy}^{(i)} &= \mathbb{E}[\mathbf{v}_i\mathbf{y}_i^T] = 
    \mathbb{E}[\mathbf{v}_i(\mathbf{d}_i + \mathbf{v}_i)^T] = \mathbf{R}_{vv}^{(i)} \ ,
\end{aligned}
\]

\vspace{-4pt}

\noindent με $\mathbf{R}_{yy}^{(i)}, \, \mathbf{R}_{vv}^{(i)}$ τους πίνακες αυτοδιακύμανσης των χρονοσειρών
$\mathbf{y}_i, \, \mathbf{v}_i$ αντίστοιχα.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\linewidth]{plot/clean_and_noisy_intervals.pdf}
    \caption{Διαστήματα με και χωρίς θόρυβο στα δεδομένα εκπαίδευσης}
    \label{fig:clean_and_noisy_intervals}
\end{figure}

Στα δεδομένα εκπαίδευσης γνωρίζουμε εκ των προτέρων τις χρονικές στιγμές κατά τις οποίες οι μετρήσεις 
περιέχουν θόρυβο (με τις στιγμές αυτές να είναι προφανώς κοινές για όλα τα κανάλια). Επίσης, από το 
Σχήμα~\ref{fig:clean_and_noisy_intervals} παρατηρούμε ότι οι χρονικές αυτές στιγμές διαμορφώνουν διαστήματα. 
Ορίζουμε επομένως:
\[
Q = \{k = 0,...,K-1:\  \mathbf{y}[k] = \mathbf{v}[k]\} \  = \  \underset{j}{{\bigcup}} Q_j
\]

\vspace{-10pt}
\noindent με $Q_j$ το $j$-οστό διάστημα όπου $\mathbf{y}[k] = \mathbf{v}[k]$ και

\vspace{-10pt}
\[
P = \{k = 0,...,K-1:\  \mathbf{y}[k] = \mathbf{d}[k] + \mathbf{v}[k]\} \ = \ \underset{j}{{\bigcup}} P_j
\]

\vspace{-10pt}
\noindent με $P_j$ το $j$-οστό διάστημα όπου $\mathbf{y}[k] = \mathbf{d}[k] + \mathbf{v}[k]$. 

\begin{examplebox}{}
    Θα εκτιμήσουμε τον πίνακα $\mathbf{R}_{vv}^{(i)}$ από τα δεδομένα απουσίας θορύβου, δηλαδή από το σύνολο $Q$.  
    Ενώ αντίστοιχα, ο πίνακας $\mathbf{R}_{yy}^{(i)}$ θα προκύψει από τα δεδομένα παρουσίας θορύβου, δηλαδή από το σύνολο $P$.
\end{examplebox}


Θεωρώντας ότι η χρονοσειρά $\mathbf{y}_i$ είναι \textit{στάσιμη} εντός κάθε διαστήματος $Q_j$, ο πίνακας
αυτοσυσχέτισης $\mathbf{R}_{vv}^{(i,j)}$ του $i$-οστού καναλιού στο $j$-οστό διάστημα, $Q_j$, όπου απουσιάζει ο 
θόρυβος είναι:
\[
    \mathbf{R}_{vv}^{(i,j)} = 
    \begin{bmatrix}
    r_v^{(i,j)}[0] & r_v^{(i,j)}[1] & \cdots & r_v^{(i,j)}[L-1] \\
    r_v^{(i,j)}[1] & r_v^{(i,j)}[0] & \cdots & r_v^{(i,j)}[L-2] \\
    \vdots & \vdots & \ddots & \vdots \\
    r_v^{(i,j)}[L-1] & r_v^{(i,j)}[L-2] & \cdots & r_v^{(i,j)}[0]
    \end{bmatrix}
\]
όπου $r_v^{(i,j)}[\tau] = \mathbb{E}[v_i[n] v_i[n + \tau]]$, με $n, \ldots, n + \tau \in Q_j$, είναι η 
συνάρτηση αυτοσυσχέτισης του $\mathbf{v}_i$ στο διάστημα $Q_j$, και $L$ η μέγιστη υστέρηση (lag). Προφανώς, 
η μέγιστη υστέρηση που θα θέσουμε θα πρέπει να είναι μικρότερη από το μικρότερο μήκος διαστήματος με ή χωρίς θόρυβο, 
δηλαδή:
\vspace{-5pt}
\[
L \leq \min\left\{ \underset{j}{\min} |Q_j|, \; \underset{j}{\min} |P_j| \right\}, 
\]

\vspace{-4pt}
\noindent όπου ο συμβολισμός $|S|$ εκφράζει το πλήθος των στοιχείων του συνόλου $S$.

\vspace{+4pt}
Από την παραπάνω ανάλυση έχουμε ότι ο πίνακας αυτοσυσχέτισης $\mathbf{R}_{vv}^{(i)}$ μπορεί να προκύψει από τον σταθμισμένο μέσο όρο όλων των 
$\mathbf{R}_{vv}^{(i,j)}$ ως εξής:

\vspace{-4pt}
\[
\mathbf{R}_{vv}^{(i)} = \frac{1}{|Q|}\sum_{j}|Q_j|\mathbf{R}_{vv}^{(i,j)}, \quad i=1,\ldots,N
\]

\vspace{-4pt}
\noindent Εργαζόμενοι κατά ανάλογο τρόπο για τα δεδομένα παρουσία θορύβου, έχουμε:

\vspace{-5pt}
\[
\mathbf{R}_{yy}^{(i)} = \frac{1}{|P|}\sum_{j}|P_j|\mathbf{R}_{yy}^{(i,j)}, \quad i=1,\ldots,N
\]

\vspace{-4pt}
\noindent Έχοντας υπολογίσει τους δύο παραπάνω πίνακες αυτοσυσχέτισης, μπορούμε να βρούμε τον πίνακα Wiener για το $i$-οστό κανάλι:
\[
\mathbf{W}^{(i)} = \mathbf{R}_{vv}^{(i)}\left(\mathbf{R}_{yy}^{(i)}\right)^{-1} \in \mathbb{R}^{L \times L}
\]

Το φίλτρο εφαρμόζεται διαδοχικά στις μετρήσεις του εκάστοτε καναλιού, σε παράθυρα μήκους $L$, σύμφωνα με 
τη σχέση:

\vspace{-5pt}
\[
\hat{\mathbf{v}}_i[k : k + L - 1] = \mathbf{W}^{(i)} \, \mathbf{y}_i[k : k + L - 1], \quad i = 1, \ldots, N.
\]

\vspace{-4pt}
\noindent Από την πάνω σχέση είναι προφανές ότι για την εκτίμηση του $\mathbf{v}_i$ χρησιμοποιούνται κάθε φορά οι τελευταίες $L$ 
μετρήσεις του $\mathbf{y}_i$.

\begin{examplebox}{Σχόλιο}
    Είναι σημαντικό να τονίσουμε σε αυτό το σημείο ότι η συνάρτηση αυτοσυσχέτισης, και συνακόλουθα ο πίνακας 
    αυτοσυσχέτισης, λαμβάνει υπόψιν μόνο γραμμικές συσχετίσεις. Συνεπώς, το φίλτρο 
    Wiener βασίζεται στην υπόθεση της γραμμικής αυτοσυσχέτισης και 
    δεν λαμβάνει υπόψιν μη γραμμικές συσχετίσεις μεταξύ των δεδομένων της χρονοσειράς.
\end{examplebox}

Στο Σχήμα~\ref{fig:single_channel_smoothing} φαίνεται η εφαρμογή του φίλτρου στα δεδομένα εκπαίδευσης 
(αριστερά) και στα δεδομένα ελέγχου (δεξιά) για το κανάλι 1. Παρατηρούμε ότι στα δεδομένα εκπαίδευσης η
εξομάλυνση των μετρήσεων όπου υπάρχει θόρυβος (διαστήματα με μεγάλες διακυμάνσεις) είναι επιτυχής με
κόστος ωστόσο την αλοίωση της πληροφοριάς στα διαστήματα όπου δεν υπάρχει θόρυβος. Επίσης, βλέπουμε ότι
στα δεδομένα ελέγχου το φίλτρο αδυνατεί να επιτύχει την αποθορυβοποίηση του σήματος όταν παρουσιάζονται
μεγάλα \selectlanguage{english}spikes\selectlanguage{greek} του δυναμικού $> 200 V$. Αυτό εξηγείται από
το γεγονός ότι το \selectlanguage{english}Wiener\selectlanguage{greek} φίλτρο βασίζεται σε στατιστικά 
χαρακτηριστικά που υπολογίζονται από τα δεδομένα εκπαίδευσης, όπου τέτοιες ακραίες τιμές δεν εμφανίζονται. 
Τα \selectlanguage{english}spikes\selectlanguage{greek} είναι μη-γραμμικά και υψηλής 
ενέργειας γεγονότα που παραβιάζουν τις υποθέσεις στάσιμης και γραμμικής συσχέτισης πάνω στις οποίες 
βασίζεται το φίλτρο, με αποτέλεσμα την αδυναμία του να τα εξομαλύνει επαρκώς.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{plot/single_channel_smoothing_train.pdf}
        \caption{}
        \label{fig:single_channel_smoothing_train}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{plot/single_channel_smoothing_test.pdf}
        \caption{}
        \label{fig:single_channel_smoothing_test}
    \end{subfigure}

    \caption{Εφαρμογή μονοκαναλικού \selectlanguage{english}Smoothing Wiener Filter\selectlanguage{greek} 
    στα α) δεδομένα εκπαίδευσης β) δεδομένα ελέγχου}
    \label{fig:single_channel_smoothing}
\end{figure}

\section*{1.2 \ Smoothing: \textit{Πολυκαναλικό} Wiener}
Μέχρι στιγμής, στην ανάλυσή μας εξετάζαμε κάθε κανάλι μεμονωμένα, αγνοώντας τη συσχέτιση που υπάρχει μεταξύ 
των μετρήσεών τους. Αυτό, ωστόσο, δεν είναι απολύτως ορθό, καθώς ο θόρυβος είναι εντονότερος στα μετωπιαία 
ηλεκτρόδια· επομένως, υπάρχει συσχέτιση μεταξύ των μετρήσεων διαφορετικών καναλιών. Στην παρούσα ενότητα θα 
συμπεριλάβουμε αυτές τις συσχετίσεις μεταξύ των καναλιών.

Έστω $\mathbf{Y}_t \in \mathbb{R}^{N \cdot L}$ το διάνυσμα υστέρησης, το οποίο περιέχει τις τιμές όλων των
καναλιών σε ένα παράθυρο μήκους $L$:
\[
\mathbf{Y}_t = 
\begin{bmatrix}
    \mathbf{y}_1[t:t+L-1] \\
    \mathbf{y}_2[t:t+L-1] \\
    \vdots \\
    \mathbf{y}_N[t:t+L-1] \\
\end{bmatrix}
\]
όπου $\mathbf{y}_i[t : t + L - 1] \in \mathbb{R}^L$ είναι οι μετρήσεις του $i$-οστού καναλιού.  
Επίσης, γράφουμε $\mathbf{Y}_t \equiv \mathbf{Y}_t^{(j)}$, με $t, \ldots, t + L - 1 \in P_j$.  
Χωρίς βλάβη της γενικότητας, θεωρούμε ότι το διάστημα $P_j$ ξεκινά από τη χρονική στιγμή $t = 1$.

Σχηματίζουμε τον πίνακα:
\[
\mathbf{Y}^{(j)} = 
\begin{bmatrix}
\mathbf{Y}_1^{(j)} \quad \mathbf{Y}_2^{(j)} \quad \cdots \quad \mathbf{Y}_T^{(j)}
\end{bmatrix}
\in \mathbb{R}^{N \cdot L \times T}, \quad T = |P_j| - L + 1,
\]
ή
\[
\mathbf{Y}^{(j)} = 
\begin{bmatrix}
    \mathbf{y}_1[1:L] & \mathbf{y}_1[2:L+1] & \cdots & \mathbf{y}_1[T-L+1:T] \\
    \mathbf{y}_2[1:L] & \mathbf{y}_2[2:L+1] & \cdots & \mathbf{y}_2[T-L+1:T] \\
    \vdots & \vdots & \ddots & \vdots \\
    \mathbf{y}_N[1:L] & \mathbf{y}_N[2:L+1] & \cdots & \mathbf{y}_N[T-L+1:T]
\end{bmatrix}
\]
Αν υποθέσουμε ότι $\mathbb{E}[\mathbf{Y}_t^{(j)}] = 0$, για κάθε $t = 1, \ldots, T$,  
τότε ο πίνακας συσχέτισης $\mathbf{R}_{yy}^{(j)}$ για το διάστημα $P_j$ δίνεται από:
\[
\mathbf{R}_{yy}^{(j)} = 
\frac{1}{T} \sum_{i=1}^T \mathbf{Y}_i^{(j)} \left(\mathbf{Y}_i^{(j)}\right)^{\top} = 
\frac{1}{T} \mathbf{Y}^{(j)} \cdot \left(\mathbf{Y}^{(j)}\right)^{\top}
\]
Αν, επιπλέον, οι χρονοσειρές δύο καναλιών $p$ και $q$ είναι από κοινού στάσιμες,  
δηλαδή ισχύει:
\[
\mathbb{E}[\mathbf{y}_p[k] \cdot \mathbf{y}_q[l]] = r_{pq}[k - l] \in \mathbb{R},
\]
δηλαδή η εταιροσυσχέτισή τους εξαρτάται μόνο από την υστέρηση $\tau = k - l$ και όχι από τον χρόνο, τότε:

\[
\mathbf{R}_{yy}^{(j)} =
\begin{bmatrix}
    \mathbf{R}_{11} & \mathbf{R}_{12} & \cdots & \mathbf{R}_{1N} \\
    \mathbf{R}_{21} & \mathbf{R}_{22} & \cdots & \mathbf{R}_{2N} \\
    \vdots & \vdots & \ddots & \vdots \\
    \mathbf{R}_{N1} & \mathbf{R}_{N2} & \cdots & \mathbf{R}_{NN}
\end{bmatrix}
\]
όπου $\mathbf{R}_{pq} \in \mathbb{R}^{L \times L}$ είναι ο πίνακας συνδιασποράς μεταξύ των καναλιών $p$ και 
$q$ για υστερήσεις $\tau = 0, \ldots, L - 1$. Το στοιχείο $[\mathbf{R}_{pq}]_{k, l} = r_{pq}[k - l]$ δείχνει
πόσο συσχετίζεται η τιμή του καναλιού $p$ για υστέρηση $k - 1$ με την τιμή του καναλιού $q$ για υστέρηση 
$l - 1$.

Όπως και στη μονοκαναλική προσέγγιση, ο πίνακας $\mathbf{R}_{yy}$ δίνεται από τον σταθμισμένο μέσο όρο  
των πινάκων διασποράς για όλα τα διαστήματα όπου υπάρχει θόρυβος:
\[
\mathbf{R}_{yy} = \frac{1}{|P|} \sum_j |P_j| \mathbf{R}_{yy}^{(j)}
\]

Εργαζόμενοι κατ' αντίστοιχο τρόπο στα διαστήματα $Q_j$ όπου απουσιάζει ο θόρυβος, προκύπτει ο πίνακας 
$\mathbf{R}_{vv}$.

Ο πίνακας Wiener (Wiener Smoothing Matrix) θα είναι:
\[
\mathbf{W} = \mathbf{R}_{vv}\mathbf{R}_{yy}^{-1} \in \mathbb{R}^{N \cdot L \times N \cdot L}
\]

Και εδώ το φίλτρο εφαρμόζεται διαδοχικά σε παράθυρα μήκους $L$ σύμφωνα με την σχέση:
\[
\hat{\mathbf{V}}_k = \mathbf{W} \cdot \mathbf{Y}_k
\] 
όπου $\hat{\mathbf{V}}_k \in \mathbb{R}^{N \cdot L}$ το διάνυσμα (πίνακας στήλης) με τις εκτιμήσεις του καθαρού 
σήματος όλων των καναλιών στο χρονικό παράθυρο $k,...,k+L-1$.

Στο Σχήμα~\ref{fig:multi_channel_smoothing} φαίνεται η εφαρμογή του φίλτρου στα δεδομένα εκπαίδευσης 
(αριστερά) και στα δεδομένα ελέγχου (δεξιά) για το κανάλι 1. Είναι εμφανές ότι, σε αυτή την περίπτωση, 
η απώλεια πληροφορίας στα καθαρά δεδομένα εκπαίδευσης είναι μικρότερη σε σχέση με τη μονοκαναλική προσέγγιση.  
Αυτό οφείλεται στο γεγονός ότι στην πολυκαναλική προσέγγιση λαμβάνουμε υπόψη τη συσχέτιση μεταξύ των καναλιών,  
οδηγώντας σε μικρότερες τιμές μέσου τετραγωνικού σφάλματος (άρα και RMSE).

Ωστόσο, παρατηρούμε και σε αυτή την περίπτωση ότι το φίλτρο αδυνατεί να εξομαλύνει 
\selectlanguage{english}spikes\selectlanguage{greek} του δυναμικού $ > 200 V$, καθώς, όπως έχουμε αναφέρει,
οφείλονται σε μη γραμμικές συσχετίσεις που δεν λαμβάνει υπόψη το φίλτρο 
\selectlanguage{english}Wiener\selectlanguage{greek}.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{plot/multi_channel_smoothing_train.pdf}
        \caption{}
        \label{fig:multi_channel_smoothing_train}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{plot/multi_channel_smoothing_test.pdf}
        \caption{}
        \label{fig:multi_channel_smoothing_test}
    \end{subfigure}

    \caption{Εφαρμογή πολυκαναλικού Smoothing Wiener Filter 
    στα α) δεδομένα εκπαίδευσης β) δεδομένα ελέγχου}
    \label{fig:multi_channel_smoothing}
\end{figure}


\section*{Υλοποίηση και Σύγκριση Φίλτρων 1.1 \& 1.2}
TODO: 
1) Πρόσθεσε σημαντικά σημεία κώδικα (key parts) με μικρή εξήγηση ώστε να βγάζει νόημα. 
2) Δώσε τα αποτελέσματα των rmse (+ πως προκύπτουν) και εξήγησε γτ είναι καλύτερο το Πολυκαναλικό (το έχουμε ήδη πει 2 φορές γτ, απλά πες ότι όντως φαίνεται να αξίζει πολύ περισσότερο και στην πράξη και ότι η διαφορά δεν είναι μικρή (κάθε άλλο)). 


\newpage 

\section*{2 \ Filtering: \textit{Πολυκαναλικό} Wiener}

\begin{examplebox}{Motivation}
    Με την παραπάνω ανάλυση που αφορούσε το Smoothing (και ιδιαίτερα την πολυκαναλική προσέγγιση) έχουμε ήδη καλύψει το βασικό πρόβλημα της υλοποίησης ενός Wiener φίλτρου για την αποθορυβοποίηση των δεδομένων μας από τα artifacts των blinks. 
    Από εδώ και πέρα υπάρχουν πολλές εναλλακτικές κατευθύνσεις τις οποίες θα μπορούσαμε να εξερευνήσουμε, χτίζοντας πάνω στην βασική ανάλυση που παραθέσαμε. 
    
    Αυτήν που στην συνέχεια θα δείξουμε είναι η περίπτωση που, αντί για Smoothing, επιλέγουμε να κάνουμε Filtering. 
    Ο λόγος για τον οποίο θεωρούμε πως έχει σημαντικό ενδιαφέρον είναι επειδή πρόκειται για μια online μέθοδο. 
    Άρα, αν θέλαμε να εφαρμόσουμε Wiener φίλτρο που να προσαρμόζει τον πίνακα $W$ σε πραγματικό χρόνο (όταν έρχεται καινούρια πληροφορία με την οποία μπορεί να κάνει training), τότε η μέθοδος που δείξαμε παραπάνω δεν θα μας ήταν χρήσιμη\textemdash μιας και όπως είδαμε σε αυτήν το signal sample εκτιμάται και από "μελλοντικά" data.
\end{examplebox}

"Στο Filtering πρόβλημα καλούμαστε να εκτιμήσουμε κάθε φορά το σήμα $\mathbf{v}[k]$ από το dataset των $[\mathbf{y}[0], \ldots, \mathbf{y}[k]]$. Το πρόβλημα αυτό είναι επαναλαμβανόμενο, για κάθε τιμή του $k$, έως ότου ολόκληρο το σήμα $\mathbf{v}[k]$, για $k = 0, 1, \ldots, K-1$ να έχει εκτιμηθεί." \\ 
(from Fundamentals of Statistical Signal Processing, Volume-i Estimation Theory)

Από το παραπάνω έχουμε ότι στόχος μας σε αυτό το πρόβλημα, για κάθε $k = 0, 1, \ldots, K-1$, είναι ο υπολογισμός του $\hat{\mathbf{v}}[k] = \mathbf{W} \cdot \mathbf{Y}_k \in \mathbb{R}^N$, όπου το $\mathbf{Y}_k\in \mathbb{R}^{N \cdot L}$ είναι όπως ορίστηκε στην προηγούμενη ανάλυση με την μόνη διαφορά ότι αναφέρεται στο dataset των $[\mathbf{y}[0], \ldots, \mathbf{y}[k]]$ (και με κατάλληλα μικρό $L$ για μικρές τιμές του $k$).

Ο δε πίνακας $W$, Wiener Filtering Matrix, αυτήν την φορά δίνεται ως:
\[
\mathbf{W} = \mathbf{r}_{vv}^{' \top}\mathbf{R}_{yy}^{-1} \in \mathbb{R}^{N \times N \cdot L}
\]
Έχουμε ήδη δείξει στο προηγούμενο Section πως προκύπτουν τα $\mathbf{Y}_k$ και $\mathbf{R}_{yy}$ από ένα dataset $[\mathbf{y}[0], \ldots, \mathbf{y}[k]]$. Το μόνο που μένει να αναλυθεί εκτενέστερα είναι το $\mathbf{r}_{vv}^{' \top}$ για το οποίο έχουμε:
\[
\mathbf{r}_{vv}^{' \top} = [\mathbf{r}_{vv}[L-1]\ \ \mathbf{r}_{vv}[L-2] \  \ldots \ \mathbf{r}_{vv}[0]] \in \mathbb{R}^{N \times N \cdot L}.
\]
Παρατηρώντας τον παραπάνω τύπο σε σχέση με αυτόν του $\mathbf{R}_{vv}$ (που προκύπτει αντίστοιχα με τον $\mathbf{R}_{yy}$), στο Wiener Smoothing Matrix, μπορεί κανείς να δει ότι υπάρχει μια αντιστοιχία στο περιεχόμενο των πινάκων. \\ 
Στην πράξη αυτό που αλλάζει είναι ότι τώρα δεν θέλουμε να εκτιμήσουμε όλες τις τιμές $[\hat{\mathbf{v}}[k-L+1], \ldots, \hat{\mathbf{v}}[k]]$ (όπως κάνουμε με το Smoothing για παράθυρα υστέρησης $L$)\textemdash παρά μόνο την τελική $\hat{\mathbf{v}}[k]$. 
Άρα, από αυτό προκύπτει ότι δεν χρειάζεται να πάρουμε τον πίνακα αυτοσυσχέτισης με όλες τις υστερήσεις $\mathbf{R}_{vv} \in \mathbb{R}^{N \cdot L \times N \cdot L}$, αλλά απλώς χρειαζόμαστε τις αυτοσυσχετίσεις που υπάρχουν στον πίνακα $\mathbf{r}_{vv}^{' \top} \in \mathbb{R}^{N \times N \cdot L}$ (που αφορούν μόνο την εκτίμηση της $\hat{\mathbf{v}}[k]$).
Οι αυτοσυσχετίσεις αυτές περιέχονται και στον πίνακα $\mathbf{R}_{vv}$, συνεπώς και ο τρόπος/υλοποίηση με τον οποίο χρειάζεται να τις υπολογίσουμε είναι ισοδύναμος της ανάλυσης που ήδη παραθέσαμε. 

\vspace{+10pt}

Έχοντας ολοκληρώσει την ανάλυση που αφορά το πρόβλημα του Filtering, μιας και πλέον για τις εκτιμήσεις των $\hat{\mathbf{v}}[k]$ όλοι οι προς υπολογισμό πίνακες έχουν εξηγηθεί, μπορούμε να περάσουμε στο επόμενο Section στο οποίο παραθέτουμε λεπτομέρειες της υλοποίησης του κώδικα και σχετικές γραφικές παραστάσεις.

\section*{Υλοποίηση και Αποτελέσματα Wiener Filtering}

Για την επίλυση του Filtering προβλήματος στο MATLAB υλοποιήσαμε την συνάρτηση: \\
function [\textit{v\_train}, \textit{v\_test}, \textit{rmse}] = \textit{wiener\_filtering\_multichannel}(\textit{x\_train}, \textit{x\_test}, \textit{blinks}, \textit{M}). \\
Αυτήν αποτελεί μία παραλλαγή της αντίστοιχης συνάρτησης για πολυκαναλικό Smoothing φίλτρο. 


Αυτήν την φορά καλούμαστε, σύμφωνα με την θεωρητική ανάλυση που παραθέσαμε, να εκτιμήσουμε όλα τα $\hat{\mathbf{v}}[k]$, ένα την φορά\textemdash μιας και λύνουμε επαναληπτικά το πρόβλημα για όλα τα υποσύνολα $[\mathbf{y}[0], \ldots, \mathbf{y}[k]]$. Αυτό έχει ως αποτέλεσμα να έχουμε μία πιο αργή επίλυση. Γι' αυτό παραθέτουμε την εφαρμογή του φίλτρου σε ένα μικρό portion του αρχικού dataset (τόσο για τα training όσο και για τα test data). 



Τρέχοντας το τελευταίο section του εκτελέσιμου MATLAB κώδικα (που μπορεί να βρεθεί \href{https://github.com/georrous6/Estimation-and-Detection-Theory/tree/main/PartB/src}{σε αυτό το repo}, μαζί με τα util functions και τα datasets) παίρνουμε τις παρακάτω γραφικές παραστάσεις. 
Στο Σχήμα~\ref{fig:multi_channel_filtering} φαίνεται η εφαρμογή του φίλτρου στα δεδομένα εκπαίδευσης 
(αριστερά) και στα δεδομένα ελέγχου (δεξιά) για το κανάλι 16. 
Η επιλογή του καναλιού που θέλουμε να κάνουμε plot μπορεί να αλλάξει μέσω της μεταβλητής \texttt{plot\_channel}
(στο αρχείο \textit{main.m} του πηγαίου κώδικα). 

\begin{figure}[ht!]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{plot/multi_channel_filtering_train.pdf}
        \caption{}
        \label{fig:multi_channel_filtering_train}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \includegraphics[width=\textwidth]{plot/multi_channel_filtering_test.pdf}
        \caption{}
        \label{fig:multi_channel_filtering_test}
    \end{subfigure}

    \caption{Εφαρμογή πολυκαναλικού Filtering Wiener Filter 
    στα α) δεδομένα εκπαίδευσης β) δεδομένα ελέγχου}
    \label{fig:multi_channel_filtering}
\end{figure}

Είναι εμφανές ότι, σε αυτή την περίπτωση, 
η απώλεια πληροφορίας στα καθαρά δεδομένα εκπαίδευσης είναι επίσης σχετικά μικρή (όπως και στην smoothing πολυκαναλική προσέγγιση).  
Αυτό οφείλεται στο γεγονός ότι στην πολυκαναλική προσέγγιση λαμβάνουμε υπόψη τη συσχέτιση μεταξύ των καναλιών,  
οδηγώντας και πάλι σε μικρές τιμές μέσου τετραγωνικού σφάλματος (άρα και RMSE).

\begin{lstlisting}[caption=Computation of Autocorrelation Matrices for Wiener Filter]
for p = 9500:size(x_train, 2)
    x_train_ = x_train(:, 1:p);
    x_test_  = x_test(:, 1:p);
    blinks_  = blinks(blinks <= p);

    [C, N] = size(x_train_);
    [cleanIntervals, noisyIntervals, max_window_size] = find_intervals(blinks_, N);

    % Same as smoothing for the x_train_ and x_test_ datasets

    % Estimate R_ss 
    % (...)
    % Estimate R_xx 
    % (...)

    % Wiener filter
    W = R_ss / R_xx;

    % Apply Wiener filter on training and testing data
    s_train = apply_wiener_filtering_multichannel(x_train_, W, M);
    s_test  = apply_wiener_filtering_multichannel(x_test_, W, M);

    v_train(:, p) = s_train(:, size(s_train, 2));
    v_test(:, p)  = s_test(:, size(s_test, 2));
end
% Compute RMSE across channels (on clean intervals only)
% ...
\end{lstlisting}

Η μέθοδος αυτή όμως, σε σχέση με την Smoothing, δεν είναι το ίδιο αποδοτική μιας και εδώ ο πίνακας $W$ με το "πέρας του χρόνου" (δηλαδή με περισσότερες μετρήσεις από το train dataset) κάνει όλο και καλύτερες προσαρμογές (ενώ η Smoothing κάνει όλες τις προσαρμογές εξ' αρχής, έχοντας πρόσβαση σε όλα τα δεδομένα). Οι προσαρμογές στον χρόνο για τον πίνακα $W$ γίνονται όσο διαβάζουμε το train dataset, ενώ για λόγους σύγκρισης χρησιμοποιούμε (κάθε χρονική στιγμή) τον ίδιο πίνακα $W$ και για το test dataset. 

\vspace{+5pt}

\textit{\textbf{Σχόλιο:}} \\
Για τον υπολογισμό του Wiener Matrix (στον κώδικα που παρατίθεται), για χάρη συνοχής και ευκολίας στην συγγραφή του κώδικα, ακολουθούμε την ίδια μέθοδο με αυτήν του Smoothing για το subset του αρχικού dataset που μελετάμε. Όπως εξηγήσαμε και στην θεωρητική ανάλυση, η διαφορά έγκειται στο ότι μας ενδιαφέρει \textit{μόνο} το $\hat{\mathbf{v}}[k]$ και όχι τα προηγούμενα lags/υστερήσεις (μιας και τις υστερήσεις τις έχουμε ήδη υπολογίσει στα προηγούμενα iterations της for loop). Θα μπορούσαμε για υπολογιστική απλότητα να αποφύγουμε τις έξτρα πράξεις (όπως δείχνουμε και στην θεωρητική ανάλυση), αλλά ούτως ή άλλως εστιάσαμε την προσοχή μας σε ένα μόνο σημείο του dataset.


\newpage

\section*{Γενική Παρατήρηση}

 Στην ανάλυση που έχουμε δείξει ως τώρα, για όλες τις διαφορετικές προσεγγίσεις εφαρμογής φίλτρων Wiener, εφαρμόζαμε το φίλτρο σε όλο το dataset\textemdash είτε υπάρχουν blinks είτε όχι. Αυτό έχει ως αποτέλεσμα στις περιπτώσεις που υπάρχουν blinks (ή τουλάχιστον που ξέρουμε ότι υπάρχουν/train dataset) να βλέπουμε όντως μια προσπάθεια αποθορυβοποίησης από το φίλτρο. Όμως στις περιπτώσεις όπου δεν υπάρχουν blinks, με το να περνάμε τα σήματα από το φίλτρο οδηγούμαστε στην αλλοίωσή τους (το φίλτρο ελαφρώς παραμορφώνει το σήμα πληροφορίας). 

 Ένας τρόπος να το αποφύγουμε αυτό είναι να εκτιμήσουμε πρώτα σε ποιά χρονικά διαστήματα του dataset υπάρχουν blinks/θόρυβος. Γνωρίζουμε από την εισαγωγή της εργασίας ότι ο θόρυβος αυτός "εμφανίζεται συχνά με πολύ μεγαλύτερο πλάτος από την κοινή εγκεφαλική δραστηριότητα που καταγράφεται από το ΗΕΓ". Επίσης ξέρουμε ότι επηρεάζει ειδικά τα μετωπιαία ηλεκτρόδια. Αξιοποιώντας αυτές τις πληροφορίες μπορούμε να εφαρμόσουμε τεχνικές ανίχνευσης των διαστημάτων όπου έχουμε blinks, μελετώντας αμιγώς τα κανάλια που αφορούν τα μετωπιαία ηλεκτρόδια. 

 Στην συνέχεια, έχοντας βρει τα διαστήματα αυτά, μπορούμε να εφαρμόσουμε Wiener φίλτρο μόνο στα σημεία όπου υπάρχουν blinks. Βέβαια είναι σημαντικό να αναφέρουμε πως η τεχνική ανίχνευσης των blinks στο dataset πρέπει να επιλεγεί με ιδιαίτερη προσοχή. Συγκεκριμένα, πρέπει η μέθοδος ανίχνευσης να μπορεί να βρίσκει με όσο το δυνατόν μεγαλύτερη πιθανότητα όλα τα δείγματα στα οποία έχουμε blinks. Με άλλα λόγια η πιθανότητα να μην ανιχνεύσουμε ένα blink πρέπει να είναι ιδιαίτερα μικρή. Αντίθετα, μπορούμε να συμβιβαστούμε (trade-off) στο να έχουμε μεγάλη πιθανότητα σε false positives, δηλαδή στο να ανιχνεύει blinks ενώ στην πραγματικότητα δεν υπάρχουν. Ο λόγος που δεν μας επηρεάζουν τόσο τα false positives είναι επειδή η εναλλακτική μας θα ήταν να περνούσαμε όλο το dataset από το φίλτρο (η παραμόρφωση του σήματος δεν είναι ιδιαίτερα μεγάλη). 


\end{document}
